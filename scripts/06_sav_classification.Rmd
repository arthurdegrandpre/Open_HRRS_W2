---
title: "06_classification"
author: "Arthur de Grandpr√©"
date: "05 feb 2021"
output: 
  html_document: 
    toc: yes
    toc_float: yes
---


# Intro

This is the sixth (last) script of the Open HRRS W2 workflow for open-source high-resolution remote sensing of vegetation cover optically complex waters.

This script is used to perform iterative random forest classifications to classify aquatic vegetation classes from other features, resulting in a vegetation cover map. The performance of this step is highly dependent on the quality of the training sets, the segmentation, and the array of features used as predictors in the random forest.

Since actual ground validation is rare, expert visual validation is used both for training and model validation. While this is not an optimal solution, existing validation data could be used at any step to enhance results. Satisfactory classification performance is attained when the expert estimates the error does not compromise the classification objectives.  

Quantitative estimates of the accuracy can be obtained through multiple methods :  
1. Separation of the training set in multiples parts : one for predicting, and the other for validation (usually 70 % / 30 % respectively).  
2. Using the out-of-bag confusion matrix from the random forest.  
3. Applying random resampling of the training set to estimate it's robustness.
  
This step requires manual work in the form of constructed training sets (multipolygon files, as shp or gpkg) built from QGIS or ArcGIS.  

It treats one image at a time, in order to allow for selection of the right training sets, and the tweaking of some parameters.

Multiple images of the same region and satellite acquisition should be able to be classified based on the same classifier training.

# 1. Setting up the R environment

## 1.1. Libraries

First, load the required libraries. They can be installed using the *install.packages("package.name", dependencies = TRUE)* function. The velox package requires the devtools library and a special function to download it from Github instead of CRAN.

```{r setup}
rm(list=ls()) ; gc()
otb.path  = "C:\\OTB-7.2.0-Win64\\bin"
otb.ramlimit = 16000

library(raster)
library(tidyverse)
library(landscapemetrics)
library(sf)
library(terra)
library(exactextractr)
library(ranger)
library(future)
library(doFuture)
library(future.apply)
```

## 1.2. Inputs / Outputs

note : I usually start by transferring "ready" images in a folder that will be used as input, preventing some messy image selection.

```{r, eval=T}
input_rasters = normalizePath(dir("../data/work/land_classification_output/water_output/",
         pattern = ".tif$",
         full.names = T,
         recursive = F))

i = 1 # raster of interest position

input_training = dir("../data/training_sets/water",
         pattern = ".gpkg$",
         full.names = T)

input_t_obj = input_training[1]


output_dir = normalizePath("../data/work/results/")
segmentation_dir = normalizePath(paste0(output_dir,"/segmentation/"))
features_dir = normalizePath(paste0(output_dir,"/features/"))
tiles_tif_output = paste0(output_dir,"/tiles/")
tiles_tif_f_output = paste0(output_dir,"/tiles_f/")
tiles_shp_output = paste0(tiles_tif_output,"/segmentation/")
tiles_classif_output = paste0(tiles_tif_output,"/classification/")
classified_output = paste0(output_dir,"/classified/")

rf_model_output = "../data/rf_models/"
```

```{r}
for(k in c(output_dir,
           segmentation_dir,
           features_dir,
           tiles_tif_output,
           tiles_shp_output,
           tiles_tif_f_output,
           tiles_classif_output,
           rf_model_output,
           classified_output)){
  if(file.exists(k)){}else{
    dir.create(k)}
}
```


## 1.3. Define functions
```{r define feature extract function, eval=T}

feature.HaralickTextureExtraction <- function(
                           raster.in = "",
                           out.path  = "",
                           name      = "",
                           channel = "1",   #default 1, selected channel index in input image
                           texture   = "simple",  #default simple, also available "advanced" or "higher"
                           parameters.min = "0", #input image minimum value
                           parameters.max = "1", #input image maximum value
                           parameters.xrad = "2", #xradius in pixels
                           parameters.yrad = "2", #yradisu in pixels
                           parameters.xoff = "1", #xoffset in pixels
                           parameters.yoff = "1", #yoffset in pixels
                           parameters.nbbin = "8" # bins per axis of histogram
                           
                           ){
  
# Set configuration      
conf <- paste("-RAM ",otb.ramlimit,
              "-in",raster.in,
              "-channel",channel,
              "-texture",texture,
              "-parameters.min",parameters.min,
              "-parameters.max",parameters.max,
              "-parameters.xrad",parameters.xrad,
              "-parameters.yrad",parameters.yrad,
              "-parameters.xoff",parameters.xoff,
              "-parameters.yoff",parameters.yoff,
              "-parameters.nbbin",parameters.nbbin,
              "-out",paste0(out.path,"/",name)
              )
  
  shell(paste("pushd ",otb.path,"&& otbcli_HaralickTextureExtraction ",conf))

write.table(x = conf,file = paste(out.path,"/",name,"_conf.txt",sep=""),row.names = F, col.names = F)
}
```


```{r define segmentation function, eval=T}
otb_seg_file = function(raster.in = NULL,
                        out.path = NULL,
                        name = "",
                        filter.meanshift.spatialr = "5",   #default 5
                        filter.meanshift.ranger   = "0.05",  #default 15
                        filter.meanshift.thres    = "0.05", #default 0.1
                        filter.meanshift.maxiter  = "100", #default 100
                        filter.meanshift.minsize  = "1",  #default 100
                        path = "C:\\OTB-7.2.0-Win64\\bin",
                        ramlimit = 16000){
  
  
  # ## test chunk
  # raster.in = normalizePath(tar_read(resample)[1])
  # name = basename(raster.in)
  # out.path = gsub("/","\\\\",output)
  # filter.meanshift.spatialr = "15"   #default 5 # 5(too many objects) to 3 (too few objects) to 4 (unbalanced)
  # filter.meanshift.ranger   = "0.03"  #default 15 # 0.01 (too many objects) to 0.05 (too few objects) to 0.02
  # filter.meanshift.thres    = "0.2" #default 0.1
  # filter.meanshift.maxiter  = "100" #default 100
  # filter.meanshift.minsize  = "1"  #default 100
  # path = "C:\\OTB-7.1.0-Win64\\bin"
  # ramlimit = 16000
  ## test chunk \
  
  otb.path <<- path
  otb.ramlimit <<- ramlimit
  
  # Set configuration      
  conf <- paste("-in",raster.in,"-filter meanshift","-filter.meanshift.spatialr",filter.meanshift.spatialr,
                "-filter.meanshift.ranger",filter.meanshift.ranger,"-filter.meanshift.thres",filter.meanshift.thres,
                "-filter.meanshift.maxiter",filter.meanshift.maxiter,"-filter.meanshift.minsize",filter.meanshift.minsize,
                "-mode vector","-mode.vector.out",paste0(out.path,"/",name,".shp"))
  
  shell(paste("pushd ",otb.path,"&& otbcli_Segmentation ",conf))
  
  write.table(x = conf,file = paste(out.path,"/",name,"_conf.txt",sep=""),row.names = F, col.names = F)
}


otb_seg_dir = function(input_source = NULL,
                       output_path = NULL,
                       filter.meanshift.spatialr = "15",   #default 5 # 5(too many objects) to 3 (too few objects) to 4 (unbalanced)
                       filter.meanshift.ranger   = "0.03",  #default 15 # 0.01 (too many objects) to 0.05 (too few objects) to 0.02
                       filter.meanshift.thres    = "0.2", #default 0.1
                       filter.meanshift.maxiter  = "100", #default 100
                       filter.meanshift.minsize  = "1",  #default 100
                       path = "C:\\OTB-7.2.0-Win64\\bin",
                       ramlimit = 16000){
  
  ### TESTING CHUNK
# output = landmask_output
# input_source = dir(paste0(".",output),full.names=T,pattern=".tif$")
# output_path = paste0(".",output, "seg")
#  filter.meanshift.spatialr = spatialr   #default 5 # 5(too many objects) to 3 (too few objects) to 4 (unbalanced)
#  filter.meanshift.ranger   = ranger  #default 15 # 0.01 (too many objects) to 0.05 (too few objects) to 0.02
# filter.meanshift.thres    = thresh #default 0.1
# filter.meanshift.maxiter  = "100" #default 100
# filter.meanshift.minsize  = "1"  #default 100
# path = otb.path
# ramlimit = 1600

  ### END OF TESTING CHUNK
  
  if(dir.exists(output_path)==F){
    dir.create(output_path)
  }else{
    unlink(dir(output_path, full.names=T))
  }
  
  otb.path <<- path
  otb.ramlimit <<- ramlimit
  
  imgs = normalizePath(input_source)
  output = normalizePath(output_path)
  
  for(i in seq_along(imgs)){
    # i=1
      otb_seg_file(raster.in = gsub("/","\\\\",normalizePath(imgs[i])),
                 out.path = gsub("/","\\\\",normalizePath(output)),
                 name = basename(input_source)[i],
                 filter.meanshift.spatialr = filter.meanshift.spatialr,   #default 5
                 filter.meanshift.ranger   = filter.meanshift.ranger,  #default 15
                 filter.meanshift.thres    = filter.meanshift.thres, #default 0.1
                 filter.meanshift.maxiter  = filter.meanshift.maxiter, #default 100
                 filter.meanshift.minsize  = filter.meanshift.minsize,  #default 100
                 path = path
    )
  }
  
  return(dir(output,full.names=T, pattern=".shp$"))
  
}

```

### Create feature stack

```{r}
#input raster

create_feature_stack = function(input_rasters = input_rasters, index = i){
  input_raster = input_rasters[index]

if(file.exists((paste0(features_dir,"/haralick")))){}else(dir.create((paste0(features_dir,"/haralick"))))

r = brick(input_raster)

feature.HaralickTextureExtraction(
                           raster.in = gsub("/","\\\\",input_raster),
                           out.path  = paste0(gsub("/","\\\\",features_dir),"\\haralick"),
                           name      = paste0("n_ht_",str_split(gsub(".*\\\\","",input_raster),"\\.")[[1]][1]),
                           channel = "8",   #default 1, selected channel index in input image
                           texture   = "simple",  #default simple, also available "advanced" or "higher"
                           parameters.min = "0", #input image minimum value
                           parameters.max = "0.3", #input image maximum value
                           parameters.xrad = "5", #xradius in pixels
                           parameters.yrad = "5", #yradius in pixels
                           parameters.xoff = "10", #xoffset in pixels
                           parameters.yoff = "10", #yoffset in pixels
                           parameters.nbbin = "64" # bins per axis of histogram
                           )

feature.HaralickTextureExtraction(
                           raster.in = gsub("/","\\\\",input_raster),
                           out.path  = paste0(gsub("/","\\\\",features_dir),"\\haralick"),
                           name      = paste0("b_ht_",str_split(gsub(".*\\\\","",input_raster),"\\.")[[1]][1]),
                           channel = "2",   #default 1, selected channel index in input image
                           texture   = "simple",  #default simple, also available "advanced" or "higher"
                           parameters.min = "0", #input image minimum value
                           parameters.max = "0.3", #input image maximum value
                           parameters.xrad = "5", #xradius in pixels
                           parameters.yrad = "5", #yradisu in pixels
                           parameters.xoff = "10", #xoffset in pixels
                           parameters.yoff = "10", #yoffset in pixels
                           parameters.nbbin = "64" # bins per axis of histogram
                           )
  
  

features = c("\\haralick")

for(j in seq_along(features)){
  r = addLayer(r, brick(dir(paste0(features_dir,features[j]),full.names=TRUE, pattern="n_??_(.*).tif$")[i]))
  r = addLayer(r, brick(dir(paste0(features_dir,features[j]),full.names=TRUE, pattern="b_??_(.*).tif$")[i]))
  }
  
  L = 0.5
  
  if(nlayers(r)==20){
  r$ndvi =  (r[[4]]-r[[3]]) / (r[[4]]+r[[3]])
  r$savi =  (1+L)*((r[[4]]-r[[3]]) / (r[[4]]+r[[3]]+L))
  r$evi  =  2.5*(((r[[4]]-r[[3]]) / (r[[4]]+6*r[[3]]-7.5*r[[1]]+1)))
  r$ndavi=  (r[[4]]-r[[1]]) / (r[[4]]+r[[1]])
  r$wavi =  (1+L)*((r[[4]]-r[[1]]) / (r[[4]]+r[[1]]+L))
  names(r) = c("B","G","R","N","NH1","NH2","NH3","NH4","NH5","NH6","NH7","NH8","BH1","BH2","BH3","BH4","BH5","BH6","BH7","BH8","NDVI","SAVI","EVI","NDAVI","WAVI")
  }else{
  r$ndvi =  (r[[8]]-r[[4]]) / (r[[8]]+r[[4]])
  r$savi =  (1+L)*((r[[8]]-r[[4]]) / (r[[8]]+r[[4]]+L))
  r$evi  =  2.5*(((r[[8]]-r[[4]]) / (r[[8]]+6*r[[4]]-7.5*r[[2]]+1)))
  r$ndavi=  (r[[8]]-r[[2]]) / (r[[8]]+r[[2]])
  r$wavi =  (1+L)*((r[[8]]-r[[2]]) / (r[[8]]+r[[2]]+L))
  names(r) = c("C","B","G","Y","R","RE","N1","N","NH1","NH2","NH3","NH4","NH5","NH6","NH7","NH8","BH1","BH2","BH3","BH4","BH5","BH6","BH7","BH8","NDVI","SAVI","EVI","NDAVI","WAVI")
  }
  
  writeRaster(r, paste0(features_dir,"\\",str_split(gsub(".*\\\\","",basename(input_raster)),"\\.")[[1]][1],".tif"), overwrite=T)

}

```


### Train

```{r}
rf_train = function(input_segments = segs2,
                    input_rasters = ras,
                    out = output){
  ### test ###
# input_segments = training_objects[training_position]
# input_rasters = input_features[features_position]
# out = model_output
  ####
  
  s = st_read("../data/training_sets/land/2019_P001_T01.gpkg")
  r = rast(input_rasters)
  
  names(r) = c("C","B","G","Y","R","RE",
               "N1","N","NH1","NH2","NH3","NH4","NH5","NH6","NH7","NH8",
               "BH1","BH2","BH3","BH4","BH5","BH6","BH7","BH8",
               "NDVI","SAVI","EVI","NDAVI","WAVI")
  
  zonal_s = exact_extract(r,s, c("min","max","mean","stdev"), progress=F)
  
  s2 = cbind(s,zonal_s) %>% 
    drop_na()
  
  mx = ranger::ranger(as.factor(class) ~ ., data = st_drop_geometry(s2[,-1]))
  
  saveRDS(mx, paste0(out,"/",basename(input_rasters),".RDS"))
  
  return(mx)
}
```

### Predict

```{r}
predict_sav = function(in_model = NULL,
                       in_raster = NULL,
                       in_seg = NULL,
                       out_path = NULL,
                       name = NULL,
                       chunk_size = 1000){
  
# test ###

  # in_model = in_model
  # in_raster = in_raster[1]
  # in_seg = in_seg[1]
  # out_path = out_path
  # name = gsub(".tif","", basename(in_raster)[1])

####

  r = rast(in_raster)
  
  if(terra::nlyr(r)==16){
    names(r) = c("b1","b2","b3","b4","b5","b6","b7","b8","ha1","ha2","ha3","ha4","ha5","ha6","ha7","ha8")
  }else{
    names(r) = c("C","B","G","Y","R","RE",
                 "N1","N","NH1","NH2","NH3","NH4","NH5","NH6","NH7","NH8",
                 "BH1","BH2","BH3","BH4","BH5","BH6","BH7","BH8",
                 "NDVI","SAVI","EVI","NDAVI","WAVI")
  }
    
  sx = crop2raster_loop(in_raster,
                   in_seg,
                   chunksize = 100000,
                   write = F)
  
  s = sx %>% 
    st_make_valid() %>% 
    dplyr::filter(st_is(.,"POLYGON")) %>% 
    dplyr::mutate(class = as.factor(NA))
  
  zx = exact_extract(r,s, c("min","max","mean","stdev"), progress=F, max_cells_in_memory = 100000)
  
    s2 = cbind(s,zx) %>%
      drop_na(4)
  
  # tryCatch({
  #   s2 = cbind(s,zx) %>%
  #     drop_na(min.b1)
  # }, error = function(e){
  #   s2 = cbind(s,zx) %>%
  #     drop_na(4)
  # }
  #   
  # )
  

  model = readRDS(in_model)
  
  sx2 = s2 %>%
    dplyr::select(-2) %>% 
    dplyr::mutate(class = ranger::predictions(stats::predict(model, st_drop_geometry(.)))) %>% 
    dplyr::group_by(class) %>% 
    dplyr::summarise() %>% 
    st_buffer(0) %>% 
    st_make_valid() %>% 
    st_write(dsn = paste0(out_path,"/",name,".gpkg"),
             driver = "GPKG",
             delete_dsn = T)

}


predict_sav_dir = function(in_model = NULL, 
                           in_raster = NULL,
                           in_seg = NULL,
                           out_path = NULL){
  #### test ###
# in_model = in_model[i]
# in_raster = dir(paste0(output,"har"), full.names=T, pattern=".tif$")
# in_seg = dir(paste0(output,"seg"),full.names=T,pattern=".shp")
# out_path = paste0(output, "pred")

  ####
  if(dir.exists(out_path)==FALSE){
    dir.create(out_path)
  }
  
  unlink(paste0(out_path,"/*"))
  
  plan(sequential)
  
  future_mapply(predict_sav,
                in_model = rep(in_model,length(in_raster)),
                in_raster = in_raster,
                in_seg = in_seg,
                out_path = rep(out_path,length(in_raster)),
                name = gsub(".tif","", basename(in_raster)),
                future.seed = TRUE)
  
  return(dir(out_path, pattern=".gpkg$", full.names=T))
  
}


crop2raster = function(raster,
                       vector,
                       output){
  
  r = rast(raster) %>% 
    terra::as.polygons(trunc = T,
                       dissolve = T,
                       values = T)
    st_as_sf() %>%
    st_make_valid()
  
  v = st_read(vector) %>%
    st_make_valid() %>%
    # terra::vect(.) %>% 
    # terra::crop(.,r) %>% 
    # terra::writeVector(.,paste0(output,"/",basename(raster)), filetype="GPKG")
    st_intersection(r) %>%
    st_write(paste0(output,"/",basename(raster),".gpkg"))
}

crop2raster_loop = function(raster,
                            vector,
                            output,
                            chunksize = 20000,
                            write = T){
  
  options("scipen"=10)
  
  r = rast(raster)
  rp = r %>%
    terra::as.polygons(trunc = T,
                       dissolve = T,
                       values = T)

  rp2 = st_as_sf(rp) %>% 
    st_make_valid()
  
  chunk_size = chunksize
  intersect_poly = rp2
  large_poly = vector
  
  for(i in 1:ceiling(as.numeric(st_layers(large_poly)[4])/chunk_size)){
    # i=279
  
    chunk=st_read(large_poly, query = paste0("SELECT * FROM \"", sf::st_layers(large_poly)[1] ,"\" LIMIT ",chunk_size," OFFSET ",ifelse(i==1,0,((i-1)*chunk_size-(i-1))))) %>% 
      st_make_valid(.) %>% 
      st_buffer(.,dist=0) %>% 
      st_transform(.,st_crs(rp2))
    
    if(i == 1){
      assign("to_fill", st_intersection(chunk,rp2)) 
    }
    
    if(i != 1){
      to_fill = bind_rows(to_fill, st_intersection(chunk,rp2))
    }
  }
  if(write==T){
    st_write(to_fill, paste0(output,"/",basename(raster),".gpkg"), driver = "GPKG", append=F)
  } else {return(to_fill)}
  
}


```

### Tile classif

```{r}
classif_tiles = function(in_haralick,
                         in_image,
                         in_model,
                         output,
                         spatialr = "15",
                         ranger = "0.03",
                         thresh = "0.2"){
  
  # ### test ###

# in_haralick = input_features[feature_position]
# in_image = input_destripe[destripe_position]
# in_model = dir(model_output, full.names=T, pattern=".RDS$")[1] # or select the right output from 2.1. Train
# output = landmask_output
# spatialr = "15"
# ranger = "0.03"
# thresh = "0.2"

  # ###
  
  if(!dir.exists(paste0(output,"/masks"))){
    dir.create(paste0(output,"/masks"))
  }
  
  foreach(i = 1:length(in_image)) %do% {
    # i=1
    if(dir.exists(output)){
      unlink(dir(output, full.names=T, ".tif"))
    }else{
      dir.create(output)
    }
    
    if(dir.exists(paste0(output,"seg"))){
      unlink(dir(paste0(output,"seg"), full.names=T))
    }else{
      dir.create(paste0(output,"seg"))
    }
    
    if(dir.exists(paste0(output,"har"))){
      unlink(dir(paste0(output,"har"), full.names=T))
    }else{
      dir.create(paste0(output,"har"))
    }
    
    if(dir.exists(paste0(output,"pred"))){
      unlink(dir(paste0(output,"pred"), full.names=T))
    }else{
      dir.create(paste0(output,"pred"))
    }
    
    # make image tiles (terra)
    # i=1
    r = terra::rast(in_image[i]) %>% 
      terra::mask(rast(in_image[i])[[1]])
    
    agg = r %>%
      aggregate(., fact = 500, fun = min)
    
    tiles = r %>% 
      makeTiles(.,
                agg,
                filename = paste0(output,"/_.tif"),
                na.rm=T)
    
    
    # make haralick tiles (terra)
    
    r = terra::rast(in_haralick[i]) %>% 
      terra::mask(rast(in_haralick[i])[[1]])
    
    agg = r %>%
      terra::aggregate(., fact = 500, fun = min)
    
    tiles = r %>% 
      terra::makeTiles(.,
                       agg,
                       filename =  paste0(output,"/har/_.tif"),
                       na.rm=T)
    
    # segment
    
    otb_seg_dir(input_source = dir(output,full.names=T,pattern=".tif$"),
                output_path = paste0(output, "seg"),
                filter.meanshift.spatialr = spatialr,   #default 5 # 5(too many objects) to 3 (too few objects) to 4 (unbalanced)
                filter.meanshift.ranger   = ranger,  #default 15 # 0.01 (too many objects) to 0.05 (too few objects) to 0.02
                filter.meanshift.thres    = thresh, #default 0.1
                filter.meanshift.maxiter  = "100", #default 100
                filter.meanshift.minsize  = "1",  #default 100
                path = otb.path,
                ramlimit = 16000)

    # predict

    predict_sav_dir(in_model = in_model[i],
                    in_raster = dir(paste0(output,"har"), full.names=T, pattern=".tif$"),
                    in_seg = dir(paste0(output,"seg"),full.names=T,pattern=".shp"),
                    out_path = paste0(output, "pred"))
    
    # merge
    ctiles = dir(paste0(output,"pred"),full.names=T,pattern=".gpkg")
    m = foreach(j = 1:length(ctiles), .combine = rbind) %do% {st_read(ctiles[j])}
    
    write = m %>%
      # filter(!str_starts(class, "l_")) %>% 
      st_write(.,driver="gpkg",paste0(output,"masks/",gsub(".tif",".gpkg",basename(in_image[i]))), delete_layer=T)
    
  }
  
  return(dir(paste0(output,"masks/"), full.names=T, pattern=".gpkg"))

}
```

# 2. Processing

## Stack
```{r}
create_feature_stack(input_raster = input_rasters, index = 1)
```

## Train
```{r}
# the crop is optional
# vect(input_t_obj) %>% 
#   terra::crop(rast(input_rasters[i])) %>% 
#   terra::writeVector(paste0("../data/training_sets/water/","crop_",basename(input_t_obj)))

# make sure to select the right training set
m = rf_train(input_segments = input_training[2],
             input_rasters = dir(features_dir, full.names=T, pattern=".tif$")[i],
             out = rf_model_output
             )

```

## Predict
```{r}
classif_tiles(
  in_haralick = dir(features_dir, full.names=T, pattern=".tif$")[i],
  in_image = input_rasters[i],
  in_model = dir(rf_model_output, full.names=T, pattern=".RDS$")[1],
  output = classified_output,
  spatialr = "5",
  ranger = "0.001",
  thresh = "0.0005"
              )

st_read(dir(paste0(classified_output,"/masks/"), full.names=T)[1]) %>% 
  plot()
```
